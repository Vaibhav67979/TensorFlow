{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGM5BouhZWeJDZEH6+yqtC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhav67979/TensorFlow/blob/main/Work/playGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdo3uvZfyAQR",
        "outputId": "a112ce52-c1bc-4882-c1d4-afd0b1c04714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "172/172 [==============================] - 25s 89ms/step - loss: 2.5534\n",
            "Epoch 2/50\n",
            "172/172 [==============================] - 15s 80ms/step - loss: 1.8619\n",
            "Epoch 3/50\n",
            "172/172 [==============================] - 17s 80ms/step - loss: 1.6164\n",
            "Epoch 4/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 1.4881\n",
            "Epoch 5/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 1.4099\n",
            "Epoch 6/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 1.3552\n",
            "Epoch 7/50\n",
            "172/172 [==============================] - 16s 80ms/step - loss: 1.3112\n",
            "Epoch 8/50\n",
            "172/172 [==============================] - 16s 78ms/step - loss: 1.2721\n",
            "Epoch 9/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 1.2356\n",
            "Epoch 10/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 1.1998\n",
            "Epoch 11/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 1.1636\n",
            "Epoch 12/50\n",
            "172/172 [==============================] - 16s 79ms/step - loss: 1.1277\n",
            "Epoch 13/50\n",
            "172/172 [==============================] - 15s 79ms/step - loss: 1.0886\n",
            "Epoch 14/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 1.0510\n",
            "Epoch 15/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 1.0092\n",
            "Epoch 16/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.9683\n",
            "Epoch 17/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.9280\n",
            "Epoch 18/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.8877\n",
            "Epoch 19/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.8497\n",
            "Epoch 20/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.8117\n",
            "Epoch 21/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.7763\n",
            "Epoch 22/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.7427\n",
            "Epoch 23/50\n",
            "172/172 [==============================] - 16s 80ms/step - loss: 0.7123\n",
            "Epoch 24/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.6836\n",
            "Epoch 25/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.6601\n",
            "Epoch 26/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.6380\n",
            "Epoch 27/50\n",
            "172/172 [==============================] - 16s 80ms/step - loss: 0.6158\n",
            "Epoch 28/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.5969\n",
            "Epoch 29/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.5779\n",
            "Epoch 30/50\n",
            "172/172 [==============================] - 16s 77ms/step - loss: 0.5640\n",
            "Epoch 31/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.5505\n",
            "Epoch 32/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.5364\n",
            "Epoch 33/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.5250\n",
            "Epoch 34/50\n",
            "172/172 [==============================] - 15s 79ms/step - loss: 0.5130\n",
            "Epoch 35/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.5045\n",
            "Epoch 36/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.4968\n",
            "Epoch 37/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.4891\n",
            "Epoch 38/50\n",
            "172/172 [==============================] - 16s 77ms/step - loss: 0.4828\n",
            "Epoch 39/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.4749\n",
            "Epoch 40/50\n",
            "172/172 [==============================] - 16s 79ms/step - loss: 0.4690\n",
            "Epoch 41/50\n",
            "172/172 [==============================] - 15s 78ms/step - loss: 0.4642\n",
            "Epoch 42/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4601\n",
            "Epoch 43/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4533\n",
            "Epoch 44/50\n",
            "172/172 [==============================] - 16s 76ms/step - loss: 0.4497\n",
            "Epoch 45/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4472\n",
            "Epoch 46/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4436\n",
            "Epoch 47/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4412\n",
            "Epoch 48/50\n",
            "172/172 [==============================] - 16s 77ms/step - loss: 0.4379\n",
            "Epoch 49/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4352\n",
            "Epoch 50/50\n",
            "172/172 [==============================] - 15s 77ms/step - loss: 0.4324\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import pad_sequences\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "# from google.colab import files\n",
        "# path_to_file = list(files.upload().keys())[0]\n",
        "\n",
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))\n",
        "\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)\n",
        "\n",
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "seq_length = 100  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell\n",
        "    target_text = chunk[1:]  # ello\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry\n",
        "\n",
        "# for x, y in dataset.take(2):\n",
        "#   print(\"\\n\\nEXAMPLE\\n\")\n",
        "#   print(\"INPUT\")\n",
        "#   print(int_to_text(x))\n",
        "#   print(\"\\nOUTPUT\")\n",
        "#   print(int_to_text(y))\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "  \n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "# checkpoint_num = 10\n",
        "# model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
        "# model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 10000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "    \n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH6Ffn0M9BZH",
        "outputId": "c3fee8c2-748e-4fd8-98fd-2083a5069de6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnIdgOY9Qdz",
        "outputId": "8d076fed-2d07-490a-9de6-f392e42c8ce1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a starting string: romeo\n",
            "romeous to lay me with the oake him: if he\n",
            "had long laugh'd him, and he singled Japua;\n",
            "She hath heret be so much.\n",
            "\n",
            "Third Citizen:\n",
            "If I be near there, his namel, I tell thee,\n",
            "Signior Hatharina, York. Menenius,\n",
            "I must have put up your queen: she shall be sworn\n",
            "The battler join'd with Oxford he to draw;\n",
            "And till we fighise 's more than you are.\n",
            "\n",
            "AUTOLYCUS:\n",
            "\n",
            "Clown:\n",
            "Then was I going prince.\n",
            "\n",
            "KING RICHARD III:\n",
            "My life more hated three-supper, now in the noble Police;\n",
            "Fair weep the stones, not for thee to fall\n",
            "Till of your treblet whom he hath contented\n",
            "Thyself no place did march amain to London,\n",
            "That way, my lord, that dayls down thy flesh and by,\n",
            "The Gaunt of England, eyes, and time in browling day.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "That thou hast wronged in thee disposed\n",
            "Prince ar for you: therefore, good speed, your queen, most gracious tribunes,\n",
            "On What musty beauteous Grumio? for a while,\n",
            "As is the father bend the king at Oxford.\n",
            "\n",
            "TYBALT:\n",
            "A whou, my lord, there are thy crown intends\n",
            "Subscribe from thee, she two have scolent and call him 'man.'\n",
            "\n",
            "KING RICHARD III:\n",
            "Be not so all the mooners. If you be, I beseech your grace\n",
            "Lord Clarence, by your time is but o'ercharped still\n",
            "O withering e soul,\n",
            "To lie fitzord.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Those are perpetual day.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "What is the axpear of that queen's life?\n",
            "Why soode his heart concerns not this preservation. FriarJUSUS:\n",
            "You wert away by 'shall'?\n",
            "After my such is fair deeds, when he accept,\n",
            "As threatening course of love a witchee\n",
            "with this foint than it.\n",
            "\n",
            "MENENIUS:\n",
            "I'll bring you there: by some charged ma, and I\n",
            "seld\n",
            "a woo chops the sinking fires me, abide\n",
            "The K:\n",
            "Ay, if this blessed heart plain, I deep sin, and many years.\n",
            "\n",
            "PETRUCHIO:\n",
            "How here bent with Romans,' OVHORK:\n",
            "Pray, for my comforts; for I am rightly traitor,\n",
            "And presume to swim, to dive no other consent,\n",
            "As that they dare nor prison. Go thou bought.\n",
            "\n",
            "PETRUCHIO:\n",
            "Alas, what name?\n",
            "\n",
            "POMPHEY:\n",
            "If boy, the govern'd of the branches yet\n",
            "In fight in peace and be found again,\n",
            "As 'twixt his resolution; were it from me,\n",
            "Tybalt?\n",
            "\n",
            "MARCIUS:\n",
            "O, sir, you must auster,\n",
            "That you do speak to the purdon erso do I.\n",
            "I will not make the penetty noble and himself\n",
            "It shame smoloughter, Tranin\n",
            "Fit for the frostrager, love? Wonten dreadful war.\n",
            "\n",
            "EDWARD:\n",
            "Where is the Duke of Gloucester and your absence; speak it in,\n",
            "And fight in justice can my wife comes King Richard; that is a\n",
            "ground may suffer: live, I am too victory, I pray, go once to thee,\n",
            "Where and reprieves stones,\n",
            "As thresent lie and lapon.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Good love, conduct thee thy friend,\n",
            "That in this best past heart upon a crown,\n",
            "Hip no more to see a ground short,\n",
            "Bit more than can my looks as thou art,\n",
            "As words to live with his chiefest thing now to the suppliant\n",
            "man.\n",
            "\n",
            "Nurse:\n",
            "Madam; you must not know it.\n",
            "Away with her! a drum, and be good on;\n",
            "Your knave hath given away to fear;\n",
            "For by the gates of God is dark to England\n",
            "And these eyes shall be.\n",
            "Here sits on his neck, an't plot the Duke of York,\n",
            "Anon expect his eyes toward the Tower, and stand asint.\n",
            "\n",
            "First Gentleman:\n",
            "Thou art thenceit.\n",
            "\n",
            "GREMIO:\n",
            "Nay, he is dead; and slaughter'd you withal,\n",
            "Pray you, a very fill of thy own king, and we shall have no better.\n",
            "\n",
            "KING EDWARD IV:\n",
            "I will prophet in this case of mine hands\n",
            "Shall bite an end.\n",
            "\n",
            "BAGOT:\n",
            "Busin by my troth, the house is death last never be\n",
            "I fear on Edward's sons, who with your stiff is born to pieces. O my fellow speaks! What,\n",
            "shall I be appointed he we? let me see the woman:\n",
            "Ay, and this, and tell them wholved how out of the day.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Where's Richard gone?\n",
            "\n",
            "CLARE:\n",
            "So had I believe thy music of?\n",
            "\n",
            "MORTAGUE:\n",
            "Thou art a traitor and a man. I think, is he as I are too children;\n",
            "And what she hath been'd another blows upon him.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "The world the French duble your father?\n",
            "\n",
            "PROSPERO:\n",
            "Nothand telling of your blood,\n",
            "My sovereign's ghostomes;\n",
            "Or shall I come to your enemies?\n",
            "\n",
            "PRINCE:\n",
            "Romeo bears, and queen is as fre drinking a weed?\n",
            "\n",
            "Pedant:\n",
            "Ay, woe the gain of the maid!\n",
            "\n",
            "AUTOLYCUS:\n",
            "y, sir.\n",
            "\n",
            "LUCIO:\n",
            "That she is worse from whence.\n",
            "\n",
            "Second Gentleman:\n",
            "'Tis a world of ape,\n",
            "Poor quiet conjern'd to the Tower, standing back.\n",
            "\n",
            "KING RICHARD III:\n",
            "What satisfactions are the prince's death;\n",
            "And then he came remore to be broil'd,\n",
            "Upon a soop he shall go.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You shall go bey than fe shall do it.\n",
            "\n",
            "CLARENCE:\n",
            "O ce you, tell me, is no fault Lucentio.\n",
            "\n",
            "ROMEO:\n",
            "There is none sit in ng in justice chance to say,\n",
            "Your profanatious strange.\n",
            "\n",
            "MARCIUS:\n",
            "Pray now you this?\n",
            "\n",
            "MAMILLIUS:\n",
            "Either visit, me;\n",
            "Depart be redeem in my tree love.\n",
            "\n",
            "KING RICHARD III:\n",
            "You have assure you: there is no more than I\n",
            "Ar as is in hard\n",
            "d happy like's old creature:\n",
            "If from this wars for his demp strange fellow that do nothing but us: I\n",
            "was the first that picits a jetter bite and ends.\n",
            "\n",
            "WARWICK:\n",
            "Exported, what you should.\n",
            "\n",
            "Nurse:\n",
            "You that it please me now,\n",
            "That shall be who foretilled from her firm eternal night.\n",
            "To London, your offence again.\n",
            "Full fathom first lay by the way.\n",
            "\n",
            "RICHARD:\n",
            "I hear some promise of such tame patience\n",
            "Dre rose\n",
            "\n",
            "POMPEY:\n",
            "Paint you, sir, be perforant!\n",
            "\n",
            "COMINIUS:\n",
            "You shall have none ily.\n",
            "\n",
            "CORIOLANUS:\n",
            "How! know you!\n",
            "Down with the ground, and Marcius,\n",
            "Thou dost subure the break of base as those whose mould be tut in him to Marcius;\n",
            "They saw ungraced by me, since I saw her father:\n",
            "Many this be executed ere you come again,\n",
            "Is ruledy more to chide away this shame,\n",
            "That fellow parting with an eyes boye of you confound is that\n",
            "He pluck'd out of the house of Lancaster.\n",
            "\n",
            "WARWICK:\n",
            "Plother, we warrant her as Henry.\n",
            "\n",
            "CLIFFORD:\n",
            "Why, that's the mighty lord?\n",
            "\n",
            "KING RICHARD III:\n",
            "Bear her mother.\n",
            "\n",
            "Shepherd:\n",
            "Come, come, you would have less to be in other suit\n",
            "And shores as nought by invy profits of devotide.\n",
            "\n",
            "CAMILLO:\n",
            "There is a slow;\n",
            "That Clifford confess shall answer his demand's most vice,\n",
            "Repair my queen.\n",
            "\n",
            "GONZALO:\n",
            "Whenonce pardons\n",
            "That I may say 'Bless; if Thomas noble fellow.\n",
            "\n",
            "TRANIO:\n",
            "'Tis well; and come, since make your bawd for requireth greeting. Now, by me, my gracious sir,\n",
            "I would be dreader for their garments of chair,\n",
            "As 'twas done call'st with the gate. So, ha! go you.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Welcome, sweet Warwick, Edward be are twos, thy sweet'st course,\n",
            "'Thould but his fears and thrust my time to wail;\n",
            "Whist'd our friends with such sweet unstinking breath;\n",
            "And to that Grey, thy heart to do\n",
            "But that's at temper onours in 'em\n",
            "to deceive. There is orrar nurse:\n",
            "I would she says not?\n",
            "\n",
            "CORIOLANUS:\n",
            "Now thou art too brive,\n",
            "it down.\n",
            "\n",
            "MONTAGUE:\n",
            "I would they were best from the weal: but they are sent\n",
            "born.\n",
            "They shall see, ever:\n",
            "'chwere's a winger learnedly delivered.\n",
            "\n",
            "ADRIAN:\n",
            "The advised men callest up, and bring aside.\n",
            "The execution in the sententious subject, as it As,\n",
            "Her suitors have more behalf.\n",
            "\n",
            "MENENIUS:\n",
            "Sirrah, no more behind.\n",
            "\n",
            "CLARENCE:\n",
            "Not after, sir; for we movethy slilif till thou knew of all thy famous last\n",
            "I never in my life.\n",
            "\n",
            "ARCHIDAMUS:\n",
            "It is four as to touch a happy thoughts\n",
            "I never wish his mouth: ours\n",
            "Did not and widow in in England,\n",
            "May into their tender lords and good fores.\n",
            "\n",
            "ESCALUS:\n",
            "Truly, sir; if I may, that calls kither of our faults,\n",
            "For she did perish swiet.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O, my disgrician:\n",
            "Well they not mine, benever to all thy wife;\n",
            "For though fond nature be thy forces hither.\n",
            "\n",
            "DUKE OF AUMERLE:\n",
            "No, my good lord; a very vial course of summer, that it shall be hor\n",
            "Than the axe too much.\n",
            "\n",
            "MERCUTIO:\n",
            "Nay, it were there, by your mistress of my broils\n",
            "Close him to his ce to your ancisory.\n",
            "Nay, now I will not, you should not be king\n",
            "With sorrow so neither. Do as thou art an all-tie?\n",
            "A God will have the child is old.\n",
            "\n",
            "PETRUCHIO:\n",
            "A herald, sir; he has is fondly with her thoughts.\n",
            "Now, by Saint Paulina's soft can come to play or the black,\n",
            "And fear you put the market-place not quickly--\n",
            "Which should themselves as triumph! and he shall: God's true, save you.\n",
            "Good maram, good night:\n",
            "Prithee bring thee to the park of hono!\n",
            "\n",
            "Marse of Lancaster;\n",
            "And he shall be a his pen down with a woman's garden,\n",
            "Do not repeal'd:\n",
            "Lay hands again be none.\n",
            "\n",
            "TRANIUS:\n",
            "As being by them not. Come, let us see\n",
            "My wife is coming.\n",
            "\n",
            "Nurse:\n",
            "Faith, I know it, by the honest country heart\n",
            "To know how canst I do appear a whit:\n",
            "Look, with all sweet bosom, knoe thou shalt free contains\n",
            "Muchis, some joyful ne: and therefore; I beseech you\n",
            "of I men marriage shows with right Venry the first\n",
            "You were a glorious turn of basiness,\n",
            "Not like to die: if Henry, youth.\n",
            "\n",
            "TRANIO:\n",
            "If it be so, then by any of the taste of time.\n",
            "I never spoke how thou hast quickly there,\n",
            "To holy accusers; a horse; and strength\n",
            "The chapell of our knees, a makiclade;\n",
            "Buf he may live with God, you take left with the\n",
            "testing on the fustfairicies of your jest:\n",
            "For shame, go banish yours.\n",
            "\n",
            "Provost:\n",
            "But why she's mine ears to thee?\n",
            "Darkl he do begen!\n",
            "Heaven and your good friends, he'ld have required\n",
            "You shall appear in free account of reason.\n",
            "\n",
            "KING LEWIS XI:\n",
            "Welcome, brave Warwick! Yord, and say I see thee\n",
            "That thou urt.\n",
            "\n",
            "SEBASTIAN:\n",
            "If she do bege,\n",
            "Such as befits the noble to be ends,\n",
            "By all lay down.\n",
            "\n",
            "PROSPERO:\n",
            "How? the best babifiace and his ropinces: if\n",
            "yet I keep his friends will person for your\n",
            "executed, and I have one thing you shall have lived\n",
            "And all the dear news in his gentle piled, and\n",
            "Hasting, that cannot feel as these\n",
            "Have moved his her; but that, being the wars!\n",
            "\n",
            "WARWICK:\n",
            "Respion o'erwords: thou hast faced for sleep,\n",
            "Ere he can spread his sweet from me.\n",
            "\n",
            "GLOUCESTER:\n",
            "He does ven bring them learn\n",
            "The Welshmen are dispersed, and Save on,\n",
            "And all the profits of the prison, hast not out\n",
            "To use his haste wherebound eyes shall enter subject moved widow.\n",
            "\n",
            "KING RICHARD III:\n",
            "The advanceme of father; there the world carry\n",
            "That have friends in the time of death;\n",
            "And that you will not now have go thy\n",
            "and what is last false Spother, big it: though there never\n",
            "Jurtly enemy is,\n",
            "And welcome home, yet measure mine honour,\n",
            "And then down false expedition thence,\n",
            "My mind presumes at our pleasure.\n",
            "\n",
            "KING RICHARD III:\n",
            "Marshal, ask yonder knight death.\n",
            "\n",
            "MARCIUS:\n",
            "I thank your worship\n"
          ]
        }
      ]
    }
  ]
}